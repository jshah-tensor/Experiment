{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1MROAG-dl4sBEMueSZ7LiliStSulNhEPA","timestamp":1752424841448},{"file_id":"1f2zuXQjFJLPZy2PxeV83cIt4fZcqVec7","timestamp":1720637615487},{"file_id":"1HAXOY_L0mdChVVCha3sNOYBoLHJCfXfi","timestamp":1719265470685},{"file_id":"1-qIYVOtYtsUfHlinbO7OXqigPSuO1en3","timestamp":1719145317554},{"file_id":"1lFUEpvDhNMBLIHZYyGfh7WZ_KtUTKd8R","timestamp":1718718396358},{"file_id":"1UyB4bT9d0kc6EXQia_h8GeTbl0LMSzu7","timestamp":1716502358736},{"file_id":"1AhE9pDCL7PWQhY1kRuCJE_1IAqjDE9wB","timestamp":1716347288850},{"file_id":"1rAsZHm-NJ2PI9nfsuYdas4ZYNDt_Wvda","timestamp":1716342389440},{"file_id":"1FW7exPJui3boL4LQgFrris7_VyLadOPq","timestamp":1716333462430},{"file_id":"1x38NIebEXGe-Qj7TxET_zmUaDMKqeWN7","timestamp":1716323424316},{"file_id":"1JvWr6K5NZ8AawQOVIrwCHKBhWJvDX4LF","timestamp":1713308670293}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Building RAG [Smart Question and Answering System]"],"metadata":{"id":"A_fZFcme18vK"}},{"cell_type":"markdown","source":["## Install Dependencies\n","\n"],"metadata":{"id":"L1KvMtf54l0d"}},{"cell_type":"code","source":["!pip install langchain==0.2.0\n","!pip install langchain-openai==0.1.7\n","!pip install langchain-community==0.2.0\n","!pip install langgraph==0.1.1\n","!pip install langchain-chroma==0.1.1\n","!pip install langchain-google-genai"],"metadata":{"id":"2evPp14fy258","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1752432914009,"user_tz":-330,"elapsed":58181,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"9237fac8-c3c0-47d4-cda5-13b5da7abac4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain==0.2.0 in /usr/local/lib/python3.11/dist-packages (0.2.0)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (2.0.41)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (3.11.15)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (0.6.7)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (0.2.43)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (0.2.4)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (0.1.147)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (1.26.4)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (2.11.7)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (2.32.3)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (8.5.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.20.1)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0) (3.26.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0) (0.9.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (4.14.1)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (3.10.18)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.0) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.0) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (2025.7.9)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.0) (3.2.3)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (4.9.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (3.0.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.2.0) (1.1.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.3.1)\n","Collecting langchain-openai==0.1.7\n","  Using cached langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: langchain-core<0.3,>=0.1.46 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.1.7) (0.2.43)\n","Requirement already satisfied: openai<2.0.0,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.1.7) (1.93.3)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.1.7) (0.9.0)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (0.1.147)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (24.2)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (2.11.7)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (8.5.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (4.14.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (0.10.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (4.67.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.1.7) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.1.7) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (2025.7.9)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (3.10.18)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.1.7) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.1.7) (2.4.0)\n","Using cached langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n","Installing collected packages: langchain-openai\n","Successfully installed langchain-openai-0.1.7\n","Collecting langchain-community==0.2.0\n","  Downloading langchain_community-0.2.0-py3-none-any.whl.metadata (8.8 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (2.0.41)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (3.11.15)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (0.6.7)\n","Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (0.2.0)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (0.2.43)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (0.1.147)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (1.26.4)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (2.32.3)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (8.5.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.20.1)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (3.26.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (0.9.0)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (0.2.4)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (2.11.7)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (4.14.1)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (3.10.18)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (2025.7.9)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.2.0) (3.2.3)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (4.9.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (0.4.1)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (1.1.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.3.1)\n","Downloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: langchain-community\n","Successfully installed langchain-community-0.2.0\n","Collecting langgraph==0.1.1\n","  Downloading langgraph-0.1.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: langchain-core<0.3,>=0.2 in /usr/local/lib/python3.11/dist-packages (from langgraph==0.1.1) (0.2.43)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.1.147)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (24.2)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (2.11.7)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (8.5.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (4.14.1)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.10.18)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (2.32.3)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph==0.1.1) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.4.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (4.9.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (2025.7.9)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.10)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (2.4.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (1.3.1)\n","Downloading langgraph-0.1.1-py3-none-any.whl (87 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: langgraph\n","Successfully installed langgraph-0.1.1\n","Collecting langchain-chroma==0.1.1\n","  Downloading langchain_chroma-0.1.1-py3-none-any.whl.metadata (1.3 kB)\n","Collecting chromadb<0.6.0,>=0.4.0 (from langchain-chroma==0.1.1)\n","  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: fastapi<1,>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma==0.1.1) (0.116.0)\n","Requirement already satisfied: langchain-core<0.3,>=0.1.40 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma==0.1.1) (0.2.43)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma==0.1.1) (1.26.4)\n","Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.2.2.post1)\n","Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2.11.7)\n","Collecting chroma-hnswlib==0.7.6 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n","Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.35.0)\n","Collecting posthog>=2.4.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading posthog-6.1.0-py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (4.14.1)\n","Collecting onnxruntime>=1.14.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n","Collecting opentelemetry-api>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading opentelemetry_instrumentation_fastapi-0.56b0-py3-none-any.whl.metadata (2.2 kB)\n","Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting tokenizers<=0.20.3,>=0.13.2 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Collecting pypika>=0.48.9 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (4.67.1)\n","Collecting overrides>=7.3.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (6.5.2)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.73.1)\n","Collecting bcrypt>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.16.0)\n","Collecting kubernetes>=28.1.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (8.5.0)\n","Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (6.0.2)\n","Collecting mmh3>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n","Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (3.10.18)\n","Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.28.1)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (13.9.4)\n","Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1,>=0.95.2->langchain-chroma==0.1.1) (0.46.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma==0.1.1) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma==0.1.1) (0.1.147)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma==0.1.1) (24.2)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.2.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (4.9.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2025.7.9)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (3.10)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.40->langchain-chroma==0.1.1) (3.0.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2.9.0.post0)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2.38.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2.32.3)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2.0.0)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (3.3.1)\n","Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2.4.0)\n","Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.40->langchain-chroma==0.1.1) (1.0.0)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (25.2.10)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (5.29.5)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.13.1)\n","Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (8.7.0)\n","Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.70.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl.metadata (1.8 kB)\n","Collecting opentelemetry-proto==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading opentelemetry_proto-1.35.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-instrumentation-asgi==0.56b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading opentelemetry_instrumentation_asgi-0.56b0-py3-none-any.whl.metadata (2.0 kB)\n","Collecting opentelemetry-instrumentation==0.56b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading opentelemetry_instrumentation-0.56b0-py3-none-any.whl.metadata (6.7 kB)\n","Collecting opentelemetry-semantic-conventions==0.56b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl.metadata (2.4 kB)\n","Collecting opentelemetry-util-http==0.56b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading opentelemetry_util_http-0.56b0-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.56b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.17.2)\n","Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.56b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading asgiref-3.9.1-py3-none-any.whl.metadata (9.3 kB)\n","Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.9.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.4.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2.19.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.33.2)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (8.2.1)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.5.4)\n","Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n","Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (15.0.1)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.3.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (4.9.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2025.3.2)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.1.5)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (3.23.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (3.4.2)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.3.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.6.1)\n","Downloading langchain_chroma-0.1.1-py3-none-any.whl (8.5 kB)\n","Downloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_proto-1.35.0-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.56b0-py3-none-any.whl (12 kB)\n","Downloading opentelemetry_instrumentation-0.56b0-py3-none-any.whl (31 kB)\n","Downloading opentelemetry_instrumentation_asgi-0.56b0-py3-none-any.whl (16 kB)\n","Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_util_http-0.56b0-py3-none-any.whl (7.6 kB)\n","Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Downloading posthog-6.1.0-py3-none-any.whl (109 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.7/109.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n","Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n","Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading asgiref-3.9.1-py3-none-any.whl (23 kB)\n","Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=63384c2dc4cbb840e236331d47f3fd6f596742c1dbb0d01615961ca87287e3d1\n","  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n","Successfully built pypika\n","Installing collected packages: pypika, durationpy, uvloop, python-dotenv, overrides, opentelemetry-util-http, opentelemetry-proto, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, tokenizers, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, langchain-chroma\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.21.2\n","    Uninstalling tokenizers-0.21.2:\n","      Successfully uninstalled tokenizers-0.21.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","transformers 4.53.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed asgiref-3.9.1 backoff-2.2.1 bcrypt-4.3.0 chroma-hnswlib-0.7.6 chromadb-0.5.23 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 langchain-chroma-0.1.1 mmh3-5.1.0 onnxruntime-1.22.1 opentelemetry-api-1.35.0 opentelemetry-exporter-otlp-proto-common-1.35.0 opentelemetry-exporter-otlp-proto-grpc-1.35.0 opentelemetry-instrumentation-0.56b0 opentelemetry-instrumentation-asgi-0.56b0 opentelemetry-instrumentation-fastapi-0.56b0 opentelemetry-proto-1.35.0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 opentelemetry-util-http-0.56b0 overrides-7.7.0 posthog-6.1.0 pypika-0.48.9 python-dotenv-1.1.1 tokenizers-0.20.3 uvloop-0.21.0 watchfiles-1.1.0\n","Collecting langchain-google-genai\n","  Downloading langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n","Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n","  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n","Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n","  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n","Collecting langchain-core<0.4.0,>=0.3.68 (from langchain-google-genai)\n","  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.11.7)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n","Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n","Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n","Collecting langsmith>=0.3.45 (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai)\n","  Downloading langsmith-0.4.5-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (6.0.2)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.14.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n","Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n","Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.3)\n","Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.73.1)\n","Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.10.18)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.23.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.9.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (2025.7.9)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.10)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.16.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.4.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.3.1)\n","Downloading langchain_google_genai-2.1.7-py3-none-any.whl (47 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n","Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.68-py3-none-any.whl (441 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.4/441.4 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langsmith-0.4.5-py3-none-any.whl (367 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.8/367.8 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: filetype, langsmith, langchain-core, google-ai-generativelanguage, langchain-google-genai\n","  Attempting uninstall: langsmith\n","    Found existing installation: langsmith 0.1.147\n","    Uninstalling langsmith-0.1.147:\n","      Successfully uninstalled langsmith-0.1.147\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.2.43\n","    Uninstalling langchain-core-0.2.43:\n","      Successfully uninstalled langchain-core-0.2.43\n","  Attempting uninstall: google-ai-generativelanguage\n","    Found existing installation: google-ai-generativelanguage 0.6.15\n","    Uninstalling google-ai-generativelanguage-0.6.15:\n","      Successfully uninstalled google-ai-generativelanguage-0.6.15\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","langgraph 0.1.1 requires langchain-core<0.3,>=0.2, but you have langchain-core 0.3.68 which is incompatible.\n","langchain-text-splitters 0.2.4 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 0.3.68 which is incompatible.\n","langchain-openai 0.1.7 requires langchain-core<0.3,>=0.1.46, but you have langchain-core 0.3.68 which is incompatible.\n","langchain 0.2.0 requires langchain-core<0.3.0,>=0.2.0, but you have langchain-core 0.3.68 which is incompatible.\n","langchain 0.2.0 requires langsmith<0.2.0,>=0.1.17, but you have langsmith 0.4.5 which is incompatible.\n","langchain-community 0.2.0 requires langchain-core<0.3.0,>=0.2.0, but you have langchain-core 0.3.68 which is incompatible.\n","langchain-community 0.2.0 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.4.5 which is incompatible.\n","langchain-chroma 0.1.1 requires langchain-core<0.3,>=0.1.40, but you have langchain-core 0.3.68 which is incompatible.\n","google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-core-0.3.68 langchain-google-genai-2.1.7 langsmith-0.4.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"93484f4fa6db4db09c80aacfc3399d8b"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Enter Open AI API Key or setup Gemini secret key in Colab"],"metadata":{"id":"H9c37cLnSrbg"}},{"cell_type":"code","source":["#from getpass import getpass\n","#OPENAI_KEY = getpass('Enter Open AI API Key: ')\n","#import os\n","#os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n","#from langchain_openai import OpenAIEmbeddings\n","#openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"],"metadata":{"id":"cv3JzCEx_PAd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752427391174,"user_tz":-330,"elapsed":2915,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"736b2fc1-f273-4238-f042-845a6f0e12b7"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter Open AI API Key: ··········\n"]}]},{"cell_type":"markdown","source":["Mounting Drive to connect with Knowedge base"],"metadata":{"id":"ifoMytiyAZaC"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TSzn3J2OrIRy","executionInfo":{"status":"ok","timestamp":1752432953272,"user_tz":-330,"elapsed":27731,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"b9254360-97d3-4d79-abb8-34005e9439cb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["### Load and Chunk Documents"],"metadata":{"id":"4_ReSz-3PVwW"}},{"cell_type":"code","source":["import json\n","from langchain.docstore.document import Document\n","from langchain.text_splitter import RecursiveCharacterTextSplitter # Still imported, but not used for splitting\n","import os # Import os module for path operations\n","import glob # Import glob for pattern matching file paths\n","import gzip # Import gzip for handling gzipped files\n","\n","docs = []\n","\n","# 'knowledgebase'\n","folder_path = '/content/drive/MyDrive/knowledge_base_adani'\n","print(f\"Attempting to load documents from dataset path: {folder_path}\")\n","\n","# Ensure the folder path exists\n","if not os.path.isdir(folder_path):\n","    print(f\"Error: Folder '{folder_path}' not found. \"\n","          f\"Please ensure the dataset 'knowledgebase' is correctly added to your Kaggle Notebook \"\n","          f\"or mounted in your Colab environment.\")\n","else:\n","    # Use glob to find all files in the specified folder.\n","    # You can add a pattern like '*.txt' or '*.md' if you only want specific file types.\n","    # For now, it will try to read all files.\n","    # Adjust the pattern if your documents have specific extensions (e.g., os.path.join(folder_path, '*.txt'))\n","    all_files_in_folder = glob.glob(os.path.join(folder_path, '*'))\n","\n","    if not all_files_in_folder:\n","        print(f\"No files found in '{folder_path}'. Please check the dataset contents.\")\n","\n","    # Loop through each file found in the folder\n","    for filepath in all_files_in_folder:\n","        # Check if it's actually a file (and not a sub-directory)\n","        if os.path.isfile(filepath):\n","            filename = os.path.basename(filepath) # Get just the file name from the full path\n","            try:\n","                with open(filepath, 'r', encoding='utf8') as f:\n","                    content = f.read()\n","                    # Create a Document object with the content and filename as metadata\n","                    docs.append(Document(page_content=content,\n","                                         metadata={'source': filename, 'path': filepath}))\n","                print(f\"Successfully loaded document: {filename}\")\n","            except Exception as e:\n","                print(f\"Error loading document {filename} (path: {filepath}): {e}\")\n","        # else:\n","        #     print(f\"Skipping non-file item: {filepath}\") # Uncomment to see skipped directories/symlinks\n","\n","\n","# --- Each document is now considered a single chunk ---\n","# Instead of splitting, we directly assign the loaded documents to chunked_docs.\n","# If you need to split the documents into smaller chunks, you can uncomment the following lines\n","# and adjust the chunk_size and chunk_overlap parameters.\n","# splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=300)\n","# chunked_docs = splitter.split_documents(docs)\n","chunked_docs = docs\n","\n","\n","print(f\"\\nTotal original documents loaded: {len(docs)}\")\n","print(f\"Total chunks created: {len(chunked_docs)}\") # This will now be the same as total documents loaded\n"],"metadata":{"id":"WwLEBC4nF9ly","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752432973298,"user_tz":-330,"elapsed":16416,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"03407f5e-3070-4fd0-df0b-6e3c617ca001"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Attempting to load documents from dataset path: /content/drive/MyDrive/knowledge_base_adani\n","Successfully loaded document: about_company.txt\n","Successfully loaded document: services_cloud.txt\n","Successfully loaded document: services_ai.txt\n","Successfully loaded document: case_study_finance.txt\n","Successfully loaded document: careers.txt\n","Successfully loaded document: genai_initiative.txt\n","Successfully loaded document: case_study_healthcare.txt\n","Successfully loaded document: vision_mission.txt\n","Successfully loaded document: leadership_team.txt\n","Successfully loaded document: training_services.txt\n","Successfully loaded document: cloud_security.txt\n","Successfully loaded document: awards.txt\n","Successfully loaded document: case_study_mfg.txt\n","Successfully loaded document: customer_testimonials.txt\n","Successfully loaded document: partners.txt\n","Successfully loaded document: contact_info.txt\n","Successfully loaded document: research_lab.txt\n","Successfully loaded document: internship_program.txt\n","Successfully loaded document: ai_governance.txt\n","Successfully loaded document: ethics_board.txt\n","Successfully loaded document: corporate_social_responsibility.txt\n","Successfully loaded document: genai_case_hr.txt\n","Successfully loaded document: product_launches.txt\n","Successfully loaded document: mlops_services.txt\n","Successfully loaded document: data_analytics_services.txt\n","Successfully loaded document: genai_case_marketing.txt\n","Successfully loaded document: sustainability_initiatives.txt\n","Successfully loaded document: technical_support.txt\n","Successfully loaded document: case_study_retail.txt\n","Successfully loaded document: conversational_ai.txt\n","\n","Total original documents loaded: 30\n","Total chunks created: 30\n"]}]},{"cell_type":"code","source":["len(chunked_docs)"],"metadata":{"id":"G4E1zYFSG7J-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752432976973,"user_tz":-330,"elapsed":68,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"51106802-d46a-4841-a6ce-65394a6a5665"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["chunked_docs[:5]"],"metadata":{"id":"aSbhERAyGw0v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752432980357,"user_tz":-330,"elapsed":23,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"ca156de5-e826-4e99-e0f8-597ce7f63085"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(metadata={'source': 'about_company.txt', 'path': '/content/drive/MyDrive/knowledge_base_adani/about_company.txt'}, page_content='FutureTech Innovations, founded in 2010, specializes in AI, cloud computing, and data analytics for enterprises.'),\n"," Document(metadata={'source': 'services_cloud.txt', 'path': '/content/drive/MyDrive/knowledge_base_adani/services_cloud.txt'}, page_content='We provide cloud migration, optimization, and management services across AWS, Azure, and GCP.'),\n"," Document(metadata={'source': 'services_ai.txt', 'path': '/content/drive/MyDrive/knowledge_base_adani/services_ai.txt'}, page_content='FutureTech offers machine learning, NLP, computer vision, and generative AI consulting services.'),\n"," Document(metadata={'source': 'case_study_finance.txt', 'path': '/content/drive/MyDrive/knowledge_base_adani/case_study_finance.txt'}, page_content=\"A financial institution reduced loan processing time by 60% using FutureTech's AI-driven document processing.\"),\n"," Document(metadata={'source': 'careers.txt', 'path': '/content/drive/MyDrive/knowledge_base_adani/careers.txt'}, page_content=\"We're hiring AI Engineers, Cloud Architects, and Data Scientists. Visit our Careers page!\")]"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["### Create a Vector DB"],"metadata":{"id":"-PnV9lAXZw9a"}},{"cell_type":"code","source":["# First, ensure you have the necessary library installed:\n","#!pip install langchain_chroma\n","\n","\n","from langchain_chroma import Chroma\n","from langchain_google_genai import GoogleGenerativeAIEmbeddings\n","import os\n","from google.colab import userdata # Import userdata for accessing secrets\n","\n","# --- Gemini API Key Setup ---\n","# It's highly recommended to load your API key from environment variables\n","# for security reasons, especially in production or shared environments like Colab.\n","# Set your API key from Colab secrets:\n","try:\n","    os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n","    print(\"Google API key loaded from Colab secrets.\")\n","except Exception as e:\n","    print(f\"Error loading Google API key from Colab secrets: {e}\")\n","    print(\"Please ensure your GOOGLE_API_KEY is set in Colab secrets.\")\n","\n","\n","# Initialize the Gemini embedding model\n","# The model name 'models/embedding-001' is commonly used for embeddings.\n","# Ensure your GOOGLE_API_KEY environment variable is set or pass it directly.\n","gemini_embed_model = None # Initialize to None\n","try:\n","    gemini_embed_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","    print(\"Gemini embedding model initialized successfully.\")\n","except Exception as e:\n","    print(f\"Error initializing Gemini embedding model: {e}\")\n","    print(\"Please ensure your GOOGLE_API_KEY environment variable is set correctly and is valid.\")\n","    # We will not exit here, but check if the model was initialized before using it.\n","\n","\n","# Assuming 'chunked_docs' is already defined from the previous steps\n","# create vector DB of docs and embeddings\n","if gemini_embed_model: # Check if the model was successfully initialized\n","    try:\n","        chroma_db = Chroma.from_documents(documents=chunked_docs,\n","                                     collection_name='rag_corporate_db',\n","                                     embedding=gemini_embed_model, # MODIFIED: Using Gemini embedding model\n","                                     # need to set the distance function to cosine else it uses euclidean by default\n","                                     # check https://docs.trychroma.com/guides#changing-the-distance-function\n","                                     collection_metadata={\"hnsw:space\": \"cosine\"},\n","                                     persist_directory=\"./corporate_db\")\n","\n","        print(\"\\nChroma DB created/loaded successfully with Gemini embeddings.\")\n","        print(f\"Number of documents in Chroma DB: {chroma_db._collection.count()}\")\n","    except Exception as e:\n","        print(f\"Error creating Chroma DB: {e}\")\n","else:\n","    print(\"\\nSkipping Chroma DB creation because Gemini embedding model failed to initialize.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1tf_EHoI0ymV","executionInfo":{"status":"ok","timestamp":1752432987507,"user_tz":-330,"elapsed":3855,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"8e4d06a0-c650-4f07-a5ca-5adac850a70e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Google API key loaded from Colab secrets.\n","Gemini embedding model initialized successfully.\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n","ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"]},{"output_type":"stream","name":"stdout","text":["\n","Chroma DB created/loaded successfully with Gemini embeddings.\n","Number of documents in Chroma DB: 30\n"]}]},{"cell_type":"markdown","source":["### Setup a Vector Database Retriever\n","\n","Here we use the following retrieval strategy:\n","\n","- Similarity with Threshold Retrieval\n"],"metadata":{"id":"bprZC4S6TLfj"}},{"cell_type":"markdown","source":["### Similarity with Threshold Retrieval\n","\n","We use cosine similarity here and retrieve the top 4 similar documents based on the user input query and also introduce a cutoff to not return any documents which are below a certain similarity threshold"],"metadata":{"id":"8foBD2xmCDYc"}},{"cell_type":"code","source":["similarity_threshold_retriever = chroma_db.as_retriever(search_type=\"similarity_score_threshold\",\n","                                                        search_kwargs={\"k\": 4,\n","                                                                       \"score_threshold\": 0.3})"],"metadata":{"id":"6ROSNwqeCMRS","executionInfo":{"status":"ok","timestamp":1752432996906,"user_tz":-330,"elapsed":5,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["query = \"About company, about Ethics, rewards, and products.\"\n","top4_docs = similarity_threshold_retriever.invoke(query)\n","top4_docs"],"metadata":{"id":"Nv93k_QpCZv7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752433005203,"user_tz":-330,"elapsed":308,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"ef8010eb-271a-4e06-db8b-359320810dd7"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"]},{"output_type":"execute_result","data":{"text/plain":["[Document(metadata={'path': '/content/drive/MyDrive/knowledge_base_adani/ethics_board.txt', 'source': 'ethics_board.txt'}, page_content='We have an independent AI Ethics Board that governs sensitive use cases and ensures regulatory compliance.'),\n"," Document(metadata={'path': '/content/drive/MyDrive/knowledge_base_adani/vision_mission.txt', 'source': 'vision_mission.txt'}, page_content='Our mission: Empower organizations through innovative technology. Vision: Ethical, sustainable AI leadership.'),\n"," Document(metadata={'path': '/content/drive/MyDrive/knowledge_base_adani/careers.txt', 'source': 'careers.txt'}, page_content=\"We're hiring AI Engineers, Cloud Architects, and Data Scientists. Visit our Careers page!\"),\n"," Document(metadata={'path': '/content/drive/MyDrive/knowledge_base_adani/data_analytics_services.txt', 'source': 'data_analytics_services.txt'}, page_content='We offer descriptive, predictive, and prescriptive analytics services across industries.')]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["query = \"what are sustainability use case?\"\n","top4_docs = similarity_threshold_retriever.invoke(query)\n","top4_docs"],"metadata":{"id":"obsI3yKOO0KL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752433048041,"user_tz":-330,"elapsed":195,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"91af8a1d-3af8-4de8-f5fd-003bac2a85da"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(metadata={'path': '/content/drive/MyDrive/knowledge_base_adani/sustainability_initiatives.txt', 'source': 'sustainability_initiatives.txt'}, page_content='FutureTech is committed to green AI practices and reducing the carbon footprint of cloud workloads.'),\n"," Document(metadata={'path': '/content/drive/MyDrive/knowledge_base_adani/corporate_social_responsibility.txt', 'source': 'corporate_social_responsibility.txt'}, page_content='FutureTech sponsors STEM education programs and AI for Good initiatives globally.'),\n"," Document(metadata={'path': '/content/drive/MyDrive/knowledge_base_adani/ethics_board.txt', 'source': 'ethics_board.txt'}, page_content='We have an independent AI Ethics Board that governs sensitive use cases and ensures regulatory compliance.'),\n"," Document(metadata={'path': '/content/drive/MyDrive/knowledge_base_adani/partners.txt', 'source': 'partners.txt'}, page_content='Our strategic partners include AWS, Microsoft Azure, Google Cloud, and Nvidia.')]"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["## Create a Query Retrieval Grader\n","\n","Here we will use an LLM itself to grade if any retrieved document is relevant to the given question - Answer will be either `yes` or `no`"],"metadata":{"id":"RXeilff0c9X5"}},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","#from langchain_openai import ChatOpenAI\n","from langchain_google_genai import ChatGoogleGenerativeAI # MODIFIED: Import Gemini chat model\n","import os\n","\n","\n","# Data model for LLM output format\n","class GradeDocuments(BaseModel):\n","    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n","    binary_score: str = Field(\n","        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n","    )\n","\n","\n","# LLM for grading\n","# MODIFIED: Using ChatGoogleGenerativeAI with 'gemini-1.5-flash-latest' model\n","try:\n","    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\", temperature=0) # MODIFIED model name\n","    structured_llm_grader = llm.with_structured_output(GradeDocuments)\n","    print(\"Gemini LLM grader initialized successfully.\")\n","except Exception as e:\n","    print(f\"Error initializing Gemini LLM grader: {e}\")\n","    print(\"Please ensure your GOOGLE_API_KEY environment variable is set correctly.\")\n","    # Exit or handle the error appropriately if the model cannot be initialized.\n","\n","\n","\n","# Prompt template for grading\n","SYS_PROMPT = \"\"\"You are an expert grader assessing relevance of a retrieved document to a user question.\n","                Follow these instructions for grading:\n","                  - If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\n","                  - Your grade should be either 'yes' or 'no' to indicate whether the document is relevant to the question or not.\n","             \"\"\"\n","grade_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", SYS_PROMPT),\n","        (\"human\", \"\"\"Retrieved document:\n","                     {document}\n","\n","                     User question:\n","                     {question}\n","                  \"\"\"),\n","    ]\n",")\n","\n","# Build grader chain\n","doc_grader = (grade_prompt\n","                  |\n","              structured_llm_grader)"],"metadata":{"id":"ubFlSqlMSU99","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752433090954,"user_tz":-330,"elapsed":61,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"f5a0710e-6f0e-4f92-b504-c7904941f2f2"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Gemini LLM grader initialized successfully.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n","\n","For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n","with: `from pydantic import BaseModel`\n","or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n","\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]}]},{"cell_type":"code","source":["query = \"Tell me about the company and ethics and governance and reward system\"\n","top4_docs = similarity_threshold_retriever.invoke(query)\n","for doc in top4_docs:\n","    print(doc.page_content)\n","    print('GRADE:', doc_grader.invoke({\"question\": query, \"document\": doc.page_content}))\n","    print()"],"metadata":{"id":"UuiAlPIbaC0W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752433102024,"user_tz":-330,"elapsed":2858,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"08c22087-6a0d-4003-9094-6dec3056a378"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["We have an independent AI Ethics Board that governs sensitive use cases and ensures regulatory compliance.\n","GRADE: binary_score='yes'\n","\n","Our mission: Empower organizations through innovative technology. Vision: Ethical, sustainable AI leadership.\n","GRADE: binary_score='yes'\n","\n","We're hiring AI Engineers, Cloud Architects, and Data Scientists. Visit our Careers page!\n","GRADE: binary_score='no'\n","\n","We offer descriptive, predictive, and prescriptive analytics services across industries.\n","GRADE: binary_score='no'\n","\n"]}]},{"cell_type":"code","source":["os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n","print(\"Google API key loaded from Colab secrets.\")\n","\n","query = \"Tell me about the company and ethics and governance and salary\"\n","top4_docs = similarity_threshold_retriever.invoke(query)\n","for doc in top4_docs:\n","    print(doc.page_content)\n","    print('GRADE:', doc_grader.invoke({\"question\": query, \"document\": doc.page_content}))\n","    print()"],"metadata":{"id":"9YNBjaO4ahnF","colab":{"base_uri":"https://localhost:8080/","height":686},"executionInfo":{"status":"error","timestamp":1752436121631,"user_tz":-330,"elapsed":850,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"8e1c2d26-f148-4eff-cc8d-8c6e1d9b2010"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Google API key loaded from Colab secrets.\n"]},{"output_type":"error","ename":"GoogleGenerativeAIError","evalue":"Error embedding content: 400 API key expired. Please renew the API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API key expired. Please renew the API key.\"\n]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/embeddings.py\u001b[0m in \u001b[0;36membed_query\u001b[0;34m(self, text, task_type, title, output_dimensionality)\u001b[0m\n\u001b[1;32m    266\u001b[0m             )\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEmbedContentResponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36membed_content\u001b[0;34m(self, request, model, content, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m   1306\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgument\u001b[0m: 400 API key expired. Please renew the API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API key expired. Please renew the API key.\"\n]","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mGoogleGenerativeAIError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-19-2884902454.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Tell me about the company and ethics and governance and salary\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtop4_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity_threshold_retriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop4_docs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/retrievers.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0m_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_other_args\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_arg_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 result = self._get_relevant_documents(\n\u001b[0m\u001b[1;32m    260\u001b[0m                     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/vectorstores/base.py\u001b[0m in \u001b[0;36m_get_relevant_documents\u001b[0;34m(self, query, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"similarity_score_threshold\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m             docs_and_similarities = (\n\u001b[0;32m-> 1082\u001b[0;31m                 self.vectorstore.similarity_search_with_relevance_scores(\n\u001b[0m\u001b[1;32m   1083\u001b[0m                     \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/vectorstores/base.py\u001b[0m in \u001b[0;36msimilarity_search_with_relevance_scores\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mscore_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score_threshold\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         docs_and_similarities = self._similarity_search_with_relevance_scores(\n\u001b[0m\u001b[1;32m    557\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/vectorstores/base.py\u001b[0m in \u001b[0;36m_similarity_search_with_relevance_scores\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \"\"\"\n\u001b[1;32m    503\u001b[0m         \u001b[0mrelevance_score_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_relevance_score_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0mdocs_and_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_search_with_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevance_score_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs_and_scores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_chroma/vectorstores.py\u001b[0m in \u001b[0;36msimilarity_search_with_score\u001b[0;34m(self, query, k, filter, where_document, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m             )\n\u001b[1;32m    472\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0mquery_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m             results = self.__query_collection(\n\u001b[1;32m    475\u001b[0m                 \u001b[0mquery_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_embedding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/embeddings.py\u001b[0m in \u001b[0;36membed_query\u001b[0;34m(self, text, task_type, title, output_dimensionality)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEmbedContentResponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mGoogleGenerativeAIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error embedding content: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mGoogleGenerativeAIError\u001b[0m: Error embedding content: 400 API key expired. Please renew the API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API key expired. Please renew the API key.\"\n]"]}]},{"cell_type":"code","source":["query = \"who won the cricket IPL match 2024?\"\n","top4_docs = similarity_threshold_retriever.invoke(query)\n","for doc in top4_docs:\n","    print(doc.page_content)\n","    print('GRADE:', doc_grader.invoke({\"question\": query, \"document\": doc.page_content}))\n","    print()"],"metadata":{"id":"8lw0moL0dWjf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752429720884,"user_tz":-330,"elapsed":2135,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"1eddb2a4-f5dd-420b-b1a9-37f424db092e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["We're hiring AI Engineers, Cloud Architects, and Data Scientists. Visit our Careers page!\n","GRADE: binary_score='no'\n","\n","We're hiring AI Engineers, Cloud Architects, and Data Scientists. Visit our Careers page!\n","GRADE: binary_score='no'\n","\n","FutureTech has won multiple AI Innovation Awards from TechWorld and CloudExpo.\n","GRADE: binary_score='no'\n","\n","FutureTech has won multiple AI Innovation Awards from TechWorld and CloudExpo.\n","GRADE: binary_score='no'\n","\n"]}]},{"cell_type":"markdown","source":["## Build a QA RAG Chain\n","\n","We will now connect our retriever to an LLM and build our QA RAG Chain"],"metadata":{"id":"Bfn4Z4Em55bb"}},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate\n","from langchain_openai import ChatOpenAI\n","from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n","from langchain_core.output_parsers import StrOutputParser\n","from operator import itemgetter\n","\n","# Create RAG prompt for response generation\n","prompt = \"\"\"You are an assistant for question-answering tasks.\n","            Use the following pieces of retrieved context to answer the question.\n","            If no context is present or if you don't know the answer, just say that you don't know the answer.\n","            Do not make up the answer unless it is there in the provided context.\n","            Give a detailed answer and to the point answer with regard to the question.\n","\n","            Question:\n","            {question}\n","\n","            Context:\n","            {context}\n","\n","            Answer:\n","         \"\"\"\n","prompt_template = ChatPromptTemplate.from_template(prompt)\n","\n","# Initialize connection with GPT-4o\n","#chatgpt = ChatOpenAI(model_name='gpt-4o', temperature=0)\n","chatgpt = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\", temperature=0)\n","\n","# Used for separating context docs with new lines\n","def format_docs(docs):\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)\n","\n","# create QA RAG chain\n","qa_rag_chain = (\n","    {\n","        \"context\": (itemgetter('context')\n","                        |\n","                    RunnableLambda(format_docs)),\n","        \"question\": itemgetter('question')\n","    }\n","      |\n","    prompt_template\n","      |\n","    chatgpt\n","      |\n","    StrOutputParser()\n",")"],"metadata":{"id":"8Pu5U9HNkl-q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["query = \"who is promoter of adani group?\"\n","top4_docs = similarity_threshold_retriever.invoke(query)\n","result = qa_rag_chain.invoke(\n","    {\"context\": top4_docs, \"question\": query}\n",")\n","print(result)"],"metadata":{"id":"9Wj-MZr2eEq8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752429751027,"user_tz":-330,"elapsed":729,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"c4d98409-f564-4be2-ce47-b1b52d7cad0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The provided text does not contain any information about the promoter of the Adani Group.  Therefore, I don't know the answer.\n"]}]},{"cell_type":"code","source":["query = \"Tell me about the company and ethics and governance and reward system\"\n","top4_docs = similarity_threshold_retriever.invoke(query)\n","result = qa_rag_chain.invoke(\n","    {\"context\": top4_docs, \"question\": query}\n",")\n","print(result)"],"metadata":{"id":"i_BK5xvbeYmz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752429793737,"user_tz":-330,"elapsed":969,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"a28490f8-ea93-40fc-ce9c-32c4129b7368"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The provided text mentions the company's commitment to ethical and sustainable AI leadership.  Specifically, it highlights the existence of an independent AI Ethics Board responsible for overseeing sensitive AI applications and maintaining regulatory compliance.  No further details about the company itself, its overall ethics and governance structure, or its reward system are given.\n"]}]},{"cell_type":"code","source":["query = \"which product you have launched on predictive ai. Let me know various cases studies or implementations?\"\n","top4_docs = similarity_threshold_retriever.invoke(query)\n","result = qa_rag_chain.invoke(\n","    {\"context\": top4_docs, \"question\": query}\n",")\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5sxD_EjT9SaE","executionInfo":{"status":"ok","timestamp":1752429920727,"user_tz":-330,"elapsed":895,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"2eccc615-e068-4b05-bf8a-743c36ec39e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Based on the provided text,  a predictive AI product offering AI recommendation engines has been launched.  A case study shows that retail clients experienced a 30% increase in personalized sales using these engines.  No other case studies or implementations are detailed in the given context.\n"]}]},{"cell_type":"markdown","source":["## Create a Query Rephraser\n","\n","We will now build a query rephraser which will use an LLM to rephrase the input user query into a better version which is optimized for web search"],"metadata":{"id":"-Fp8Eh0x5bMY"}},{"cell_type":"code","source":["# LLM for question rewriting\n","# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\", temperature=0)\n","\n","\n","# Prompt template for rewriting\n","SYS_PROMPT = \"\"\"Act as a question re-writer and perform the following task:\n","                 - Convert the following input question to a better version that is optimized for web search.\n","                 - When re-writing, look at the input question and try to reason about the underlying semantic intent / meaning.\n","             \"\"\"\n","re_write_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", SYS_PROMPT),\n","        (\"human\", \"\"\"Here is the initial question:\n","                     {question}\n","\n","                     Formulate an improved question.\n","                  \"\"\",\n","        ),\n","    ]\n",")\n","# Create rephraser chain\n","question_rewriter = (re_write_prompt\n","                        |\n","                       llm\n","                        |\n","                     StrOutputParser())"],"metadata":{"id":"Mm7T22tmfYWj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["query = \"which are employee friendly policies\"\n","question_rewriter.invoke({\"question\": query})"],"metadata":{"id":"2bGCpLKzhTUr","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1752430105937,"user_tz":-330,"elapsed":354,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"d8fbb94e-7610-4152-da4d-1e129196250e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Best employee-friendly company policies'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":84}]},{"cell_type":"code","source":["query = \"which product you have launched on predictive ai. Let me know various cases studies or implementations?\"\n","query = question_rewriter.invoke({\"question\": query})\n","print(query)\n","\n","top4_docs = similarity_threshold_retriever.invoke(query)\n","result = qa_rag_chain.invoke(\n","    {\"context\": top4_docs, \"question\": query}\n",")\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pf4WnFmS-Y-y","executionInfo":{"status":"ok","timestamp":1752430232345,"user_tz":-330,"elapsed":2827,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"bf863d76-b06d-4fda-f3c4-ef37945eb216"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Here are a few improved questions, each targeting slightly different aspects of the original query:\n","\n","**Option 1 (Broadest):**\n","\n","\"Predictive AI case studies and implementations: Which products use this technology?\"\n","\n","**Option 2 (More specific, focusing on a particular company -  requires knowing the company name):**\n","\n","\"[Company Name] predictive AI products: case studies and implementations\"  (Replace \"[Company Name]\" with the actual company name)\n","\n","\n","**Option 3 (Focuses on specific applications):**\n","\n","\"Predictive AI applications and case studies in [Industry/Area]\" (Replace \"[Industry/Area]\" with a relevant field like healthcare, finance, etc.)\n","\n","\n","**Option 4 (If interested in open-source solutions):**\n","\n","\"Open-source predictive AI projects: case studies and implementations\"\n","\n","\n","The improvements include:\n","\n","* **Clarity:**  The original question is grammatically awkward. The revised options are clearer and more concise.\n","* **Keywords:**  The revised options use more precise keywords that search engines are likely to recognize.\n","* **Specificity:** The options offer variations to allow for more targeted searches depending on the user's needs.\n","\n","\n","The best option will depend on the context and what the user is specifically looking for.\n","Based on the provided text, one example of a predictive AI implementation is the use of AI recommendation engines in retail.  These engines resulted in a 30% uplift in personalized sales for retail clients.  The text does not offer information on other products, companies, industries, or open-source projects using predictive AI.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ccaae7e","executionInfo":{"status":"ok","timestamp":1752431445719,"user_tz":-330,"elapsed":1732,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"5dd04a19-a87a-4d4e-8a55-ba3af4b8d58d"},"source":["!pip install pydantic<2"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: 2: No such file or directory\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":498},"id":"18758434","executionInfo":{"status":"ok","timestamp":1752431496915,"user_tz":-330,"elapsed":5048,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"e4f46c2c-c90d-42de-dc35-4dc2b2a6365c"},"source":["!pip install pydantic==1.10.13"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pydantic==1.10.13\n","  Downloading pydantic-1.10.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (149 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/149.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m143.4/149.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==1.10.13) (4.14.1)\n","Downloading pydantic-1.10.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pydantic\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 2.11.7\n","    Uninstalling pydantic-2.11.7:\n","      Successfully uninstalled pydantic-2.11.7\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","langchain-google-genai 2.1.7 requires langchain-core<0.4.0,>=0.3.68, but you have langchain-core 0.2.43 which is incompatible.\n","langchain-google-genai 2.1.7 requires pydantic<3,>=2, but you have pydantic 1.10.13 which is incompatible.\n","google-genai 1.24.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.13 which is incompatible.\n","gradio 5.31.0 requires pydantic<2.12,>=2.0, but you have pydantic 1.10.13 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","thinc 8.3.6 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.13 which is incompatible.\n","albumentations 2.0.8 requires pydantic>=2.9.2, but you have pydantic 1.10.13 which is incompatible.\n","google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pydantic-1.10.13\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydantic"]},"id":"b663c9c5441f42b686abd8711ac7b253"}},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":984},"id":"370ddfe5","executionInfo":{"status":"ok","timestamp":1752432274689,"user_tz":-330,"elapsed":5122,"user":{"displayName":"SHAH JINAL MUKESHKUMAR","userId":"18144195439990939151"}},"outputId":"1ba68bdf-2855-42fb-c894-c0852c8adaa7"},"source":["!pip install --upgrade langchain-core"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.2.43)\n","Collecting langchain-core\n","  Using cached langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n","Collecting langsmith>=0.3.45 (from langchain-core)\n","  Using cached langsmith-0.4.5-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (6.0.2)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.14.1)\n","Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.11.7)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core) (3.10.18)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core) (2.32.3)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core) (0.23.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (0.4.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core) (4.9.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core) (2025.7.9)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core) (3.10)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core) (0.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core) (2.4.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core) (1.3.1)\n","Using cached langchain_core-0.3.68-py3-none-any.whl (441 kB)\n","Using cached langsmith-0.4.5-py3-none-any.whl (367 kB)\n","Installing collected packages: langsmith, langchain-core\n","  Attempting uninstall: langsmith\n","    Found existing installation: langsmith 0.1.147\n","    Uninstalling langsmith-0.1.147:\n","      Successfully uninstalled langsmith-0.1.147\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.2.43\n","    Uninstalling langchain-core-0.2.43:\n","      Successfully uninstalled langchain-core-0.2.43\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","langgraph 0.1.1 requires langchain-core<0.3,>=0.2, but you have langchain-core 0.3.68 which is incompatible.\n","langchain-text-splitters 0.2.4 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 0.3.68 which is incompatible.\n","langchain-openai 0.1.7 requires langchain-core<0.3,>=0.1.46, but you have langchain-core 0.3.68 which is incompatible.\n","langchain 0.2.0 requires langchain-core<0.3.0,>=0.2.0, but you have langchain-core 0.3.68 which is incompatible.\n","langchain 0.2.0 requires langsmith<0.2.0,>=0.1.17, but you have langsmith 0.4.5 which is incompatible.\n","langchain-community 0.2.0 requires langchain-core<0.3.0,>=0.2.0, but you have langchain-core 0.3.68 which is incompatible.\n","langchain-community 0.2.0 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.4.5 which is incompatible.\n","langchain-chroma 0.1.1 requires langchain-core<0.3,>=0.1.40, but you have langchain-core 0.3.68 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed langchain-core-0.3.68 langsmith-0.4.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["langchain_core","langsmith"]},"id":"64900131a1394bc795115af566e9e2ba"}},"metadata":{}}]}]}